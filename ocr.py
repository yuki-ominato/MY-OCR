import os
import sys
import tkinter as tk
from PIL import Image, ImageGrab, ImageOps
import ctypes
import keyboard
import threading
import pyperclip
import numpy as np
from keras.models import load_model
import cv2
from scipy import ndimage
import datetime

# è‡ªä½œOCRãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = load_model("saved_models/font_recognition_model.keras")

# ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«
LABELS = list("0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz?")

# DPIã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç„¡åŠ¹åŒ–
ctypes.windll.user32.SetProcessDPIAware()

def preprocess_image(image):
    """
    ç”»åƒã®å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°
    """
    img_rgb = image.convert("RGBA")
    img = np.array(img_rgb)

    img_np = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)
    for i in range(img_np.shape[0]):
        for j in range(img_np.shape[1]):
            img_np[i][j] = (img[i][j][0] * 0.2126 + img[i][j][1] * 0.7152 + img[i][j][2] * 0.0722) * img[i][j][3] / 255.0
    
    # äºŒå€¤åŒ–å‡¦ç†ã‚’è¿½åŠ  (ä»¥å‰ã®å¤§æ´¥ã®äºŒå€¤åŒ–ã«æˆ»ã™)
    _, binary = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    return binary

def detect_characters(image):
    """
    æ–‡å­—é ˜åŸŸã‚’æ¤œå‡ºã™ã‚‹é–¢æ•°
    """
    # è¼ªéƒ­æ¤œå‡º
    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # print(f"[DEBUG] Detected {len(contours)} contours.") # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    
    # æ–‡å­—é ˜åŸŸã®æŠ½å‡º
    char_regions = []
    for i, contour in enumerate(contours):
        x, y, w, h = cv2.boundingRect(contour)
        # print(f"[DEBUG] Contour {i}: x={x}, y={y}, w={w}, h={h}") # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if w > 10 and h > 10:  # å°ã•ã™ãã‚‹é ˜åŸŸã¯é™¤å¤–
            char_regions.append((x, y, w, h))
    
    return char_regions

def postprocess_text(text):
    """
    èªè­˜çµæœã®å¾Œå‡¦ç†ã‚’è¡Œã†é–¢æ•°
    """
    # ç©ºç™½æ–‡å­—ã®å‰Šé™¤
    text = text.strip()
    
    # é€£ç¶šã™ã‚‹åŒã˜æ–‡å­—ã®å‰Šé™¤ï¼ˆä¾‹ï¼š'AA' â†’ 'A'ï¼‰
    result = ''
    for i in range(len(text)):
        if i == 0 or text[i] != text[i-1]:
            result += text[i]
    
    return result

def Check_Binary(img, check_name):
    # print(img.shape)
    # print(img)
    flag = False
    for h in range(img.shape[0]):
        for w in range(img.shape[1]):
            num = img[h][w]
            if num != 0 and num != 255:
                print("f{check_name} is Not Binary")
                flag = True
                break
        if flag:
            break

class ScreenOCRApp:
    def __init__(self):
        self.start_x = None
        self.start_y = None
        self.rect = None

        self.root = tk.Tk()
        self.root.attributes("-alpha", 0.3)
        self.root.attributes("-topmost", True)
        self.root.overrideredirect(True)
        self.root.geometry(f"{self.root.winfo_screenwidth()}x{self.root.winfo_screenheight()}+0+0")

        self.canvas = tk.Canvas(self.root, cursor="cross", bg="black")
        self.canvas.pack(fill=tk.BOTH, expand=True)

        self.canvas.bind("<ButtonPress-1>", self.on_button_press)
        self.canvas.bind("<B1-Motion>", self.on_move_press)
        self.canvas.bind("<ButtonRelease-1>", self.on_button_release)

        self.root.mainloop()

    def on_button_press(self, event):
        self.start_x = self.canvas.canvasx(event.x)
        self.start_y = self.canvas.canvasy(event.y)
        self.rect = self.canvas.create_rectangle(
            self.start_x, self.start_y, self.start_x, self.start_y,
            outline='red', width=2
        )

    def on_move_press(self, event):
        cur_x, cur_y = (self.canvas.canvasx(event.x), self.canvas.canvasy(event.y))
        self.canvas.coords(self.rect, self.start_x, self.start_y, cur_x, cur_y)

    def on_button_release(self, event):
        end_x = self.canvas.canvasx(event.x)
        end_y = self.canvas.canvasy(event.y)

        self.root.destroy()

        x1 = int(min(self.start_x, end_x))
        y1 = int(min(self.start_y, end_y))
        x2 = int(max(self.start_x, end_x))
        y2 = int(max(self.start_y, end_y))

        # ç”»åƒã®å–å¾—
        img = ImageGrab.grab(bbox=(x1, y1, x2, y2))
        
        # å‰å‡¦ç†
        processed_img = preprocess_image(img)
        Check_Binary(processed_img, "processed_img")
        save_img = Image.fromarray(processed_img)
        save_img.save("debug_images/processed_img.png")
        
        # æ–‡å­—æ¤œå‡º
        char_regions = detect_characters(processed_img)
        
        # æ–‡å­—èªè­˜
        recognized_text = ""
        # ä¿å­˜ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        save_dir = "debug_images"
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            
        for i, (x, y, w, h) in enumerate(char_regions):
            char_img = processed_img[y:y+h, x:x+w]
            char_img = Image.fromarray(char_img)
            char_img = char_img.resize((38, 38))
            img_array = np.array(char_img) / 255.0
            img_array = img_array.reshape(1, 38, 38, 1)

            # img_arrayã‚’ç”»åƒã¨ã—ã¦ä¿å­˜
            save_array = (img_array[0, :, :, 0] * 255).astype(np.uint8)
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(save_dir, f"char_array_{timestamp}_{i}.png")
            cv2.imwrite(save_path, save_array)

            prediction = model.predict(img_array, verbose=0)
            label_index = np.argmax(prediction)
            print(label_index)
            char = LABELS[label_index]
            recognized_text += char
        
        # å¾Œå‡¦ç†
        # final_text = postprocess_text(recognized_text)

        print("===== OCRçµæœï¼ˆè‡ªä½œãƒ¢ãƒ‡ãƒ«ï¼‰ =====")
        # print(final_text)
        print(recognized_text)
        print("===============================")
        # pyperclip.copy(final_text)
        pyperclip.copy(recognized_text)
        print("â–¶ çµæœã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")

def run_ocr():
    threading.Thread(target=ScreenOCRApp).start()

def quit_app():
    print("ğŸ”š ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
    os._exit(0)

keyboard.add_hotkey('ctrl+shift+f', run_ocr)
keyboard.add_hotkey("ctrl+shift+q", quit_app)

print("ğŸ” Ctrl + Shift + F ã‚’æŠ¼ã™ã¨OCRãƒ¢ãƒ¼ãƒ‰ãŒèµ·å‹•ã—ã¾ã™ï¼ˆè‡ªä½œãƒ¢ãƒ‡ãƒ«ï¼‰")
print("âŒ Ctrl + Shift + Q ã§çµ‚äº†")

keyboard.wait()

